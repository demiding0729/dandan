import csv
import pandas as pd
import numpy as np
import re
from datetime import datetime
from sklearn.model_selection import train_test_split
from libsvm.python.svmutil import *

# define a function used for finding a word in a sentence
def findWholeWord(w):
    return re.compile(r'\b({0})\b'.format(w), flags=re.IGNORECASE).search
 
myfile = open('positives.csv', 'r')
mylist = [line.split("', '") for line in myfile.readlines()] # extract each word from the line
for i in mylist:
    i[-1] = i[-1].strip() # delete '\n' of last term
    
# we need to flatten this 2-D list into 1-D
my_newlist = []
for sublist in mylist:
    for item in sublist:
        my_newlist.append(item)
        
my_newlist
print(len(my_newlist))
myfile = open('negatives.csv', 'r')
mylist = [line.split("', '") for line in myfile.readlines()] # extract each word from the line
for i in mylist:
    i[-1] = i[-1].strip() # delete '\n' of last term
    
# we need to flatten this 2-D list into 1-D
for sublist in mylist:
    for item in sublist:
        my_newlist.append(item)
        
my_newlist

print(len(my_newlist))

myfile = open('offtopics.csv', 'r')
mylist = [line.split("', '") for line in myfile.readlines()] # extract each word from the line
for i in mylist:
    i[-1] = i[-1].strip() # delete '\n' of last term
    
# we need to flatten this 2-D list into 1-D
for sublist in mylist:
    for item in sublist:
        my_newlist.append(item)
        
my_newlist
print(len(my_newlist))
# export the list of unique words
csvfile = "word.csv"
with open(csvfile, "w") as output:
    writer = csv.writer(output, lineterminator='\n')
    for val in np.unique(list(np.asarray(my_newlist))):
        writer.writerow([val])  
# remember to manually clean the "word.csv" before we read it again

# read the list of words
words_ori = [line.strip() for line in open('words.csv', 'r').readlines()]
words = list(np.unique(list(np.asarray(words_ori))))
words

data = pd.read_csv('positive.csv', names = ['Original_text'], encoding='ISO-8859-1')
data

for i in words:
    for j in range(len(data.Original_text)):
        if findWholeWord(str(i))(str(data.Original_text[j])) == None:
            data.loc[j, i] = 0
        else:
            data.loc[j, i] = 1
            
data['label'] = 1
data
data.to_csv('positives_processed.csv')
data = pd.read_csv('negative.csv', names = ['Original_text'], encoding='ISO-8859-1')
data
for i in words:
    for j in range(len(data.Original_text)):
        if findWholeWord(str(i))(str(data.Original_text[j])) == None:
            data.loc[j, i] = 0
        else:
            data.loc[j, i] = 1
            
data['label'] = 1
data
data.to_csv('negatives_processed.csv')

data = pd.read_csv('offtopic.csv', names = ['Original_text'], encoding='ISO-8859-1')
data
for i in words:
    for j in range(len(data.Original_text)):
        if findWholeWord(str(i))(str(data.Original_text[j])) == None:
            data.loc[j, i] = 0
        else:
            data.loc[j, i] = 1
            
data['label'] = 0
data
data.to_csv('offtopics_processed.csv')

data_positive = pd.read_csv("positives_processed.csv").iloc[:, 1:]
data_negative = pd.read_csv("negatives_processed.csv").iloc[:, 1:]
data_offtopic = pd.read_csv("offtopics_processed.csv").iloc[:, 1:]
data = pd.concat([data_positive, data_negative, data_offtopic], ignore_index=True)
data

x = data.iloc[:, 1:2190]
y = data.iloc[:, -1]

x = np.asarray(x)
y = np.asarray(y)

x.shape

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33, random_state = 43)
y_train

param = svm_parameter("-q")
problem = svm_problem(y_train, x_train)

results = []
# this loop is used for tuning the hyper-parameters
for c in range(-3, 10):
    for g in range(-8, 4):
        for k in range(0, 4):
            param.C, param.gamma, param.kernel_type = 2**c, 2**g, k
            m = svm_train(problem, param)
            p_y, p_acc, p_val = svm_predict(y_test, x_test, m)
            results.append([param.C, param.gamma, param.kernel_type, p_acc[0]])
            
# select the best hyper-parameters (with the highest test accuracy)
bestIdx = np.argmax([np.array(results)[:, 3]])
print('\nBest parameter:', results[bestIdx])
param.C, param.gamma, param.kernel_type = results[bestIdx][0], results[bestIdx][1], results[bestIdx][2]
m = svm_train(problem, param)
pred_y, pred_acc, pred_val = svm_predict(y_test, x_test, m)
label = pd.DataFrame([y_test, pred_y]).T
label.columns = ['actual', 'prediction']
label

# Compute TP,FP,FN,TN for the above classification
TP = sum((np.asarray(pred_y) == 1)&(y_test == 1))
FP = sum((np.asarray(pred_y) == 1)&(y_test == 0))
FN = sum((np.asarray(pred_y) == 0)&(y_test == 1))
TN = sum((np.asarray(pred_y) == 0)&(y_test == 0))

# Compute accuracy, recall and precision
Accuracy = 100.0 * (TP + TN)/(TP + TN + FP + FN)
Recall = 100.0 * TP/(TP + FN)
Precision = 100.0 * TP/(TP + FP)
print('Accuracy = %.2f%%\nRecall = %.2f%%\nPrecision = %.2f%%'%(Accuracy, Recall, Precision))

myfile = open('Round2/textdate1.csv', 'r', encoding='ISO-8859-1')
mylist = [line.split(" +0000 2019") for line in myfile.readlines()]
for i in mylist:
    i[-1] = i[-1].strip() # delete '\n' of last term
mylist

df = pd.DataFrame(mylist)
df.columns = ['Original_date', 'Original_text']
df

df.Original_date[0] = 'Fri Mar 01 20:08:19'
for i in words:
    df[i] = 0
df

for i in range(len(words)):
    for j in range(len(df.Original_text)):
        if findWholeWord(words[i])(df.Original_text[j]) != None:
            df.iloc[j, i+2] = 1
df
df.to_csv('Round2/textdate1_processed.csv')
data = pd.read_csv("Round2/textdate1_processed.csv").iloc[:, 1:]
data
data['label'] = 0
data

x = data.iloc[:, 2:2191]
y = data.label

x = np.asarray(x)
y = np.asarray(y)
x.shape

pred_y, pred_acc, pred_val = svm_predict(y, x, m)
data['label'] = pred_y

data['Original_date'] = pd.to_datetime(data['Original_date'], format='%a %b %d %X')
data.Original_date = data.Original_date.apply(lambda dt: dt.replace(year = 2019))
data

new_data = data.sort_values(by = ['Original_date'])
new_data.reset_index().iloc[:, 1:].to_csv("Round2/results.csv")

result = pd.read_csv("Round2/results.csv").iloc[:, 1:]
result['Original_date'] = pd.to_datetime(result['Original_date'])
result

day = result.Original_date.dt.day.unique()
total = []
label1 = []

for i in day:
    total.append(sum(result.Original_date.dt.day == i))
    label1.append(sum((result.Original_date.dt.day == i) & (result.label == 1)))
count = pd.DataFrame([day, label1, total]).T
count.columns = ['day', 'label1', 'total']
count

count.to_csv("Round2/counts.csv")

data_positive = pd.read_csv("positives_processed.csv").iloc[:, 1:]
data_negative = pd.read_csv("negatives_processed.csv").iloc[:, 1:]
data_negative.label = 0
data = pd.concat([data_positive, data_negative], ignore_index=True)
data

x = data.iloc[:, 1:2190]
y = data.iloc[:, -1]

x = np.asarray(x)
y = np.asarray(y)
x.shape

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33, random_state = 43)
y_train

param = svm_parameter("-q")
problem = svm_problem(y_train, x_train)

results = []
# this loop is used for tuning the hyper-parameters
for c in range(-3, 10):
    for g in range(-8, 4):
        for k in range(0, 4):
            param.C, param.gamma, param.kernel_type = 2**c, 2**g, k
            m = svm_train(problem, param)
            p_y, p_acc, p_val = svm_predict(y_test, x_test, m)
            results.append([param.C, param.gamma, param.kernel_type, p_acc[0]])
            
# select the best hyper-parameters (with the highest test accuracy)
bestIdx = np.argmax([np.array(results)[:, 3]])
print('\nBest parameter:', results[bestIdx])


param.C, param.gamma, param.kernel_type = results[bestIdx][0], results[bestIdx][1], results[bestIdx][2]
m = svm_train(problem, param)
pred_y, pred_acc, pred_val = svm_predict(y_test, x_test, m)

label = pd.DataFrame([y_test, pred_y]).T
label.columns = ['actual', 'prediction']
label

# Compute TP,FP,FN,TN for the above classification
TP = sum((np.asarray(pred_y) == 1)&(y_test == 1))
FP = sum((np.asarray(pred_y) == 1)&(y_test == 0))
FN = sum((np.asarray(pred_y) == 0)&(y_test == 1))
TN = sum((np.asarray(pred_y) == 0)&(y_test == 0))

# Compute accuracy, recall and precision
Accuracy = 100.0 * (TP + TN)/(TP + TN + FP + FN)
Recall = 100.0 * TP/(TP + FN)
Precision = 100.0 * TP/(TP + FP)
print('Accuracy = %.2f%%\nRecall = %.2f%%\nPrecision = %.2f%%'%(Accuracy, Recall, Precision))

data = pd.read_csv("Round2/results.csv").iloc[:, 1:]
data = data.loc[data.label == 1]
data.label = 0
data

x = data.iloc[:, 2:2191]
y = data.label

x = np.asarray(x)
y = np.asarray(y)
x.shape

pred_y, pred_acc, pred_val = svm_predict(y, x, m)
data['label'] = pred_y
data

data.to_csv("Round2/results_only_posi_nega.csv")

result = pd.read_csv("Round2/results_only_posi_nega.csv").iloc[:, 1:]
result['Original_date'] = pd.to_datetime(result['Original_date'])
result

day = result.Original_date.dt.day.unique()
label0 = []
label1 = []

for i in day:
    label0.append(sum((result.Original_date.dt.day == i) & (result.label == 0)))
    label1.append(sum((result.Original_date.dt.day == i) & (result.label == 1)))
    
count = pd.DataFrame({'day': day,
                      'label0': label0,
                      'label1': label1})
count['total'] = count['label0'] + count['label1']
count

count.to_csv("Round2/counts_only_posi_nega.csv")












